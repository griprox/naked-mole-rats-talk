{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82167e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gr1/miniconda3/envs/nmr/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "path_to_this_notebook = os.path.abspath('.')\n",
    "PATH_TO_PROJECT = path_to_this_notebook[: path_to_this_notebook.find('notebooks')]\n",
    "sys.path.append(PATH_TO_PROJECT)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.deep_learning.soundtype_classifier.classifier_datasets import create_data_for_classifier\n",
    "from src.metadata_processing.load_data import load_recordings_metadata, load_sounds\n",
    "from collections import defaultdict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5087bc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "berlin_im-augment=5_nfft=512_nmel=80_tdim=64_rec-denoise=False_highpass=3000\n"
     ]
    }
   ],
   "source": [
    "path_to_recordings_metadata = PATH_TO_PROJECT + 'data/'\n",
    "recordings_metadata_name = 'recordings_metadata.csv'\n",
    "\n",
    "# What data to use\n",
    "dates = 'all'\n",
    "colonies = ['stark', 'lannister', 'martell', 'targaryen', 'baratheon', 'tyrell', 'arryn']\n",
    "# colonies = ['hvdkleinannotated']\n",
    "experiments = 'all'\n",
    "stages = ['traced and checked', 'labeled and checked', 'split and checked',]\n",
    "classes_to_drop = ['weirdo', 'badsplit', 'noise', 'sound']\n",
    "max_sounds_per_class = {'softchirp': 4000}\n",
    "max_sound_length = 12000\n",
    "min_sound_length = 1337\n",
    "min_sound_occurrences = 30\n",
    "# Denoising parameters\n",
    "use_rec_denoising = False\n",
    "rec_denoising_params = {'stationary': False, 'n_fft': 512, 'time_constant_s': 0.05, \n",
    "                        'freq_mask_smooth_hz': 500, 'time_mask_smooth_ms': 10}\n",
    "# Sounds metadata parameters\n",
    "classes_balance_factor = 5/7\n",
    "train_ratio = .7\n",
    "columns_to_copy = ['colony', 'ratids', 'date', 'experiment']\n",
    "# Processing features\n",
    "frequency_threshold = 3000\n",
    "sr = 22050\n",
    "n_fft = 512\n",
    "n_mel = 80\n",
    "t_dim = 64\n",
    "target_shape = (n_mel, t_dim)\n",
    "use_melspecs = True\n",
    "# Data augmentation parameters\n",
    "wave_augment_params = {'augment': False, \n",
    "                       'times_each_sound': 4, \n",
    "                       'stretching_lims': None,\n",
    "                       'add_noise_lims': (0.001, 0.005), }\n",
    "times_augment_im = 5\n",
    "#times_augment_im = 10\n",
    "augment_im = True\n",
    "# Where to store\n",
    "path_to_save = PATH_TO_PROJECT + 'models/classifier/datasets/'\n",
    "augment_str = 'no-augment' if (times_augment_im == 1 or not augment_im) else 'im-augment=%d' % times_augment_im\n",
    "dataset_name = 'berlin_%s_nfft=%d_nmel=%d_tdim=%d_rec-denoise=%s_highpass=%s' % (augment_str, n_fft, \n",
    "                                                                                 n_mel, t_dim, use_rec_denoising, \n",
    "                                                                                 frequency_threshold)\n",
    "random_seed = 42\n",
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2af1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 944 recordings\n"
     ]
    }
   ],
   "source": [
    "recs_metadata, recs_dict = load_recordings_metadata(path_to_recordings_metadata, recordings_metadata_name,\n",
    "                                                    dates, colonies, experiments, stages, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eadbf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config dictionary\n",
    "all_params_dict = {'sr': sr,\n",
    "                   \n",
    "                   'recs_metadata': \n",
    "                       {'dates': dates, 'colonies': colonies, 'experiments': experiments, 'stages': stages,\n",
    "                        'path_to_recordings_metadata': path_to_recordings_metadata, \n",
    "                        'recordings_metadata_name': recordings_metadata_name},\n",
    "                   \n",
    "                   'rec_denoising':\n",
    "                       {'use_rec_denoising': use_rec_denoising, 'rec_denoising_params': rec_denoising_params},\n",
    "                   \n",
    "                   'sounds_metadata':\n",
    "                       {'classes_to_drop': classes_to_drop, 'max_sounds_per_class': max_sounds_per_class, \n",
    "                        'max_sound_length': max_sound_length, 'min_sound_length': min_sound_length, \n",
    "                        'min_sound_occurrences': min_sound_occurrences,\n",
    "                        'classes_balance_factor': classes_balance_factor, 'train_ratio': train_ratio,\n",
    "                        'columns_to_copy': columns_to_copy, 'random_seed': random_seed},\n",
    "                   \n",
    "                   'features': \n",
    "                       {'target_shape': target_shape, 'frequency_threshold': frequency_threshold,\n",
    "                        'n_fft': n_fft, 'n_mel': n_mel, 'wave_augment_params': wave_augment_params, \n",
    "                        'use_melspecs': use_melspecs,  'times_augment_im': times_augment_im, \n",
    "                        'augment_im': augment_im}\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4a05536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 944 recordings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gr1/Projects/naked-mole-rats/src/metadata_processing/process_sounds_metadata.py:37: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  sounds_metadata = pd.concat(sounds_metadata, 0).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 484 recordings (5005 sounds)for train and  208 recordings (2091 sounds)for test\n",
      "\n",
      "############ Classes in train:############ \n",
      "\n",
      "softchirp      2819\n",
      "downsweep       543\n",
      "pupcombo        444\n",
      "whistle         216\n",
      "combotwo        180\n",
      "combo           168\n",
      "scream          124\n",
      "pupcheveron     122\n",
      "loudchirp       118\n",
      "grunt           101\n",
      "upsweep          84\n",
      "pupsquawk        66\n",
      "hiccup           20\n",
      "Name: cl, dtype: int64\n",
      "############ Classes in test: ############ \n",
      "\n",
      "softchirp      1177\n",
      "pupcombo        248\n",
      "downsweep       202\n",
      "whistle          99\n",
      "combotwo         65\n",
      "combo            59\n",
      "grunt            56\n",
      "pupcheveron      56\n",
      "scream           46\n",
      "pupsquawk        35\n",
      "upsweep          27\n",
      "loudchirp        18\n",
      "hiccup            3\n",
      "Name: cl, dtype: int64\n",
      "After balancing:\n",
      "############ Classes in train:############ \n",
      "\n",
      "softchirp      2819\n",
      "downsweep       543\n",
      "pupcombo        444\n",
      "whistle         216\n",
      "combotwo        180\n",
      "combo           168\n",
      "scream          124\n",
      "pupcheveron     122\n",
      "loudchirp       118\n",
      "grunt           101\n",
      "upsweep          84\n",
      "pupsquawk        66\n",
      "hiccup           20\n",
      "Name: cl, dtype: int64\n",
      "############ Classes in test: ############ \n",
      "\n",
      "softchirp      1177\n",
      "pupcombo        248\n",
      "downsweep       202\n",
      "whistle          99\n",
      "combotwo         65\n",
      "combo            59\n",
      "grunt            56\n",
      "pupcheveron      56\n",
      "scream           46\n",
      "pupsquawk        35\n",
      "upsweep          27\n",
      "loudchirp        18\n",
      "hiccup            3\n",
      "Name: cl, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gr1/Projects/naked-mole-rats/src/deep_learning/soundtype_classifier/classifier_datasets.py:79: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  for sound in sounds_npy_train])\n",
      "/home/gr1/Projects/naked-mole-rats/src/deep_learning/soundtype_classifier/classifier_datasets.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  for sound in sounds_npy_test])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'extract_specs_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16178/2686858333.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                \u001b[0mpath_to_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                \u001b[0mpreloaded_recs_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecs_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                                balance_train=False)\n\u001b[0m",
      "\u001b[0;32m~/Projects/naked-mole-rats/src/deep_learning/soundtype_classifier/classifier_datasets.py\u001b[0m in \u001b[0;36mcreate_data_for_classifier\u001b[0;34m(all_params_dict, dataset_name, path_to_save, save, preloaded_recs_dict, balance_train)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# Extract spectrograms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0muse_melspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_params_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_melspecs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mextract_specs_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_params_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'extract_specs_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mn_fft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_params_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_fft'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mn_mel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_params_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_mel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'extract_specs_params'"
     ]
    }
   ],
   "source": [
    "# Create and save datasets\n",
    "(all_classes, sounds_metadata_train, sounds_npy_train, melspecs_train,  sounds_metadata_test, \n",
    " sounds_npy_test,  melspecs_test) = create_data_for_classifier(all_params_dict, dataset_name, \n",
    "                                                               path_to_save, save=False, \n",
    "                                                               preloaded_recs_dict=recs_dict,\n",
    "                                                               balance_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "263191fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5005"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2819 + 543+ 444 + 216 + 180 + 168 + 124 + 122 + 118 + 101 + 84 + 66 + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004983c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8b2ffc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1595 4225 2295 1680 1575]\n",
      "[  8 192 217  43   7]\n"
     ]
    }
   ],
   "source": [
    "# Print bincounts\n",
    "img_shape = melspecs_train.shape[1:]\n",
    "y_train_str = sounds_metadata_train['cl']\n",
    "y_test_str = sounds_metadata_test['cl']\n",
    "all_classes_str = sorted(list(set(y_train_str.unique()) | set(y_test_str.unique())))\n",
    "y_train = y_train_str.apply(lambda x: all_classes_str.index(x))\n",
    "y_test = y_test_str.apply(lambda x: all_classes_str.index(x))\n",
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285af2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
