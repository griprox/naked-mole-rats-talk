{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d82167e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "path_to_this_notebook = os.path.abspath('.')\n",
    "PATH_TO_PROJECT = path_to_this_notebook[: path_to_this_notebook.find('notebooks')]\n",
    "sys.path.append(PATH_TO_PROJECT)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.deep_learning.soundtype_classifier.classifier_datasets import create_data_for_classifier\n",
    "from src.metadata_processing.load_data import load_recordings_metadata, load_sounds\n",
    "from collections import defaultdict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5087bc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "berlin_new-specs_im-augment=5_nfft=512_shape=(128, 64)_denoise=False_hpass=3000\n"
     ]
    }
   ],
   "source": [
    "path_to_recordings_metadata = PATH_TO_PROJECT + 'data/'\n",
    "recordings_metadata_name = 'recordings_metadata.csv'\n",
    "\n",
    "# What data to use\n",
    "dates = 'all'\n",
    "colonies = ['stark', 'lannister', 'martell', 'targaryen', 'baratheon', 'tyrell', 'arryn']\n",
    "# colonies = ['hvdkleinannotated']\n",
    "experiments = 'all'\n",
    "stages = ['traced and checked', 'labeled and checked', 'split and checked',]\n",
    "classes_to_drop = ['weirdo', 'badsplit', 'noise', 'sound']\n",
    "max_sounds_per_class = {'softchirp': 4000}\n",
    "max_sound_length = 12000\n",
    "min_sound_length = 1337\n",
    "min_sound_occurrences = 30\n",
    "\n",
    "# Denoising parameters\n",
    "use_rec_denoising = False\n",
    "rec_denoising_params = {'stationary': False, 'n_fft': 512, 'time_constant_s': 0.05, \n",
    "                        'freq_mask_smooth_hz': 500, 'time_mask_smooth_ms': 10}\n",
    "\n",
    "# Sounds metadata parameters\n",
    "classes_balance_factor = 5/7\n",
    "train_ratio = .7\n",
    "columns_to_copy = ['colony', 'ratids', 'date', 'experiment']\n",
    "\n",
    "# Processing features\n",
    "extract_specs_params = {'num_freq_bins': 128,\n",
    "                        'num_time_bins': 64,\n",
    "                        'nperseg': 512, \n",
    "                        'noverlap': None, \n",
    "                        'min_freq': 3000,\n",
    "                        'max_freq': 11025,\n",
    "                        'spec_min_val': -10, \n",
    "                        'spec_max_val': 0,\n",
    "                        'remove_dc_offset': True, \n",
    "                        'mel': False, \n",
    "                        'max_dur': 0.4, \n",
    "                        'time_stretch': True}\n",
    "sr = 22050\n",
    "highpass_filtering = 3000\n",
    "specs_type = 'new-specs' # 'mel' , 'specs', 'new-specs'\n",
    "target_shape = (extract_specs_params['num_freq_bins'], extract_specs_params['num_time_bins'])\n",
    "\n",
    "# Data augmentation parameters\n",
    "wave_augment_params = {'augment': False, \n",
    "                       'times_each_sound': 1, \n",
    "                       'stretching_lims': None,\n",
    "                       'add_noise_lims': (0.001, 0.005), }\n",
    "times_augment_im = 5\n",
    "augment_im = True\n",
    "\n",
    "# Where to store\n",
    "path_to_save = PATH_TO_PROJECT + 'models/classifier/datasets/'\n",
    "\n",
    "data_str = 'berlin'\n",
    "augment_str = 'no-augment' if (times_augment_im == 1 or not augment_im) else 'im-augment=%d' % times_augment_im\n",
    "\n",
    "dataset_name = '%s_%s_%s_nfft=%d_shape=%s_denoise=%s_hpass=%s' % (data_str, specs_type, augment_str,\n",
    "                                                                  extract_specs_params['nperseg'],\n",
    "                                                                  target_shape,  use_rec_denoising, \n",
    "                                                                  highpass_filtering)\n",
    "random_seed = 42\n",
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a2af1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 904 recordings\n"
     ]
    }
   ],
   "source": [
    "recs_metadata, recs_dict = load_recordings_metadata(path_to_recordings_metadata, recordings_metadata_name,\n",
    "                                                    dates, colonies, experiments, stages, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eadbf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config dictionary\n",
    "all_params_dict = {'sr': sr,\n",
    "                   \n",
    "                   'recs_metadata': \n",
    "                       {'dates': dates, 'colonies': colonies, 'experiments': experiments, 'stages': stages,\n",
    "                        'path_to_recordings_metadata': path_to_recordings_metadata, \n",
    "                        'recordings_metadata_name': recordings_metadata_name},\n",
    "                   \n",
    "                   'rec_denoising':\n",
    "                       {'use_rec_denoising': use_rec_denoising, 'rec_denoising_params': rec_denoising_params},\n",
    "                   \n",
    "                   'sounds_metadata':\n",
    "                       {'classes_to_drop': classes_to_drop, 'max_sounds_per_class': max_sounds_per_class, \n",
    "                        'max_sound_length': max_sound_length, 'min_sound_length': min_sound_length, \n",
    "                        'min_sound_occurrences': min_sound_occurrences,\n",
    "                        'classes_balance_factor': classes_balance_factor, 'train_ratio': train_ratio,\n",
    "                        'columns_to_copy': columns_to_copy, 'random_seed': random_seed},\n",
    "                   \n",
    "                   'features': \n",
    "                       {'target_shape': target_shape, 'highpass_filtering': highpass_filtering,\n",
    "                        'wave_augment_params': wave_augment_params,  \n",
    "                        'extract_specs_params': extract_specs_params, 'specs_type': specs_type, \n",
    "                        'times_augment_im': times_augment_im, 'augment_im': augment_im}\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4a05536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 904 recordings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gr1/Projects/naked-mole-rats/src/metadata_processing/process_sounds_metadata.py:37: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  sounds_metadata = pd.concat(sounds_metadata, 0).reset_index(drop=True)\n",
      "/home/gr1/Projects/naked-mole-rats/src/deep_learning/soundtype_classifier/classifier_datasets.py:26: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  return pd.concat(sounds_metadata_balanced, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 464 recordings (5275 sounds)for train and  200 recordings (1824 sounds)for test\n",
      "\n",
      "############ Classes in train:############ \n",
      "\n",
      "softchirp      2894\n",
      "downsweep       553\n",
      "pupcombo        477\n",
      "whistle         256\n",
      "combotwo        219\n",
      "combo           189\n",
      "scream          170\n",
      "grunt           120\n",
      "loudchirp       117\n",
      "pupcheveron     108\n",
      "upsweep          92\n",
      "pupsquawk        63\n",
      "hiccup           17\n",
      "Name: cl, dtype: int64\n",
      "############ Classes in test: ############ \n",
      "\n",
      "softchirp      1105\n",
      "pupcombo        215\n",
      "downsweep       192\n",
      "pupcheveron      70\n",
      "whistle          59\n",
      "combo            38\n",
      "pupsquawk        38\n",
      "grunt            37\n",
      "combotwo         26\n",
      "upsweep          19\n",
      "loudchirp        19\n",
      "hiccup            6\n",
      "Name: cl, dtype: int64\n",
      "After balancing:\n",
      "############ Classes in train:############ \n",
      "\n",
      "softchirp      2894\n",
      "downsweep      1659\n",
      "pupcombo       1431\n",
      "combo          1323\n",
      "combotwo       1314\n",
      "whistle        1280\n",
      "scream         1190\n",
      "grunt          1080\n",
      "pupcheveron    1080\n",
      "loudchirp      1053\n",
      "upsweep        1012\n",
      "pupsquawk       945\n",
      "hiccup          663\n",
      "Name: cl, dtype: int64\n",
      "############ Classes in test: ############ \n",
      "\n",
      "softchirp      1105\n",
      "pupcombo        215\n",
      "downsweep       192\n",
      "pupcheveron      70\n",
      "whistle          59\n",
      "combo            38\n",
      "pupsquawk        38\n",
      "grunt            37\n",
      "combotwo         26\n",
      "upsweep          19\n",
      "loudchirp        19\n",
      "hiccup            6\n",
      "Name: cl, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gr1/Projects/naked-mole-rats/src/deep_learning/soundtype_classifier/classifier_datasets.py:79: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  for sound in sounds_npy_train])\n",
      "/home/gr1/Projects/naked-mole-rats/src/deep_learning/soundtype_classifier/classifier_datasets.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  for sound in sounds_npy_test])\n",
      "/home/gr1/Projects/naked-mole-rats/src/deep_learning/soundtype_classifier/classifier_datasets.py:108: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  for _ in range(times_augment_im):\n",
      "/home/gr1/miniconda3/envs/nmr/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/gr1/miniconda3/envs/nmr/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved !!! \n"
     ]
    }
   ],
   "source": [
    "# Create and save datasets\n",
    "(all_classes, sounds_metadata_train, sounds_npy_train, melspecs_train,  sounds_metadata_test, \n",
    " sounds_npy_test,  melspecs_test) = create_data_for_classifier(all_params_dict, dataset_name, \n",
    "                                                               path_to_save, save=True, \n",
    "                                                               preloaded_recs_dict=recs_dict,\n",
    "                                                               balance_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea8b2ffc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6615  6570  8295  5400  3315  5265  5400  7155  4725  5950 14470  5060\n",
      "  6400]\n",
      "[  38   26  192   37    6   19   70  215   38    0 1105   19   59]\n"
     ]
    }
   ],
   "source": [
    "# Print bincounts\n",
    "img_shape = melspecs_train.shape[1:]\n",
    "y_train_str = sounds_metadata_train['cl']\n",
    "y_test_str = sounds_metadata_test['cl']\n",
    "all_classes_str = sorted(list(set(y_train_str.unique()) | set(y_test_str.unique())))\n",
    "y_train = y_train_str.apply(lambda x: all_classes_str.index(x))\n",
    "y_test = y_test_str.apply(lambda x: all_classes_str.index(x))\n",
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
