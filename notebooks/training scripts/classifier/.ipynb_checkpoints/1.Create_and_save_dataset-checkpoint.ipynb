{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82167e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gr1/miniconda3/envs/nmr/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "path_to_this_notebook = os.path.abspath('.')\n",
    "PATH_TO_PROJECT = path_to_this_notebook[: path_to_this_notebook.find('notebooks')]\n",
    "sys.path.append(PATH_TO_PROJECT)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.deep_learning.soundtype_classifier.classifier_datasets import create_data_for_classifier\n",
    "from src.metadata_processing.load_data import load_recordings_metadata, load_sounds\n",
    "from collections import defaultdict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5087bc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hvd_im-augment=5_nfft=512_nmel=80_tdim=64_rec-denoise=False_highpass=3000\n"
     ]
    }
   ],
   "source": [
    "path_to_recordings_metadata = PATH_TO_PROJECT + 'data/'\n",
    "recordings_metadata_name = 'recordings_metadata.csv'\n",
    "\n",
    "# What data to use\n",
    "dates = 'all'\n",
    "colonies = ['stark', 'lannister', 'martell', 'targaryen', 'baratheon', 'tyrell', 'arryn']\n",
    "colonies = ['hvdkleinannotated']\n",
    "experiments = 'all'\n",
    "stages = ['traced and checked', 'labeled and checked', 'split and checked',]\n",
    "classes_to_drop = ['weirdo', 'badsplit', 'noise', 'sound']\n",
    "max_sounds_per_class = {'softchirp': 4000}\n",
    "max_sound_length = 12000\n",
    "min_sound_length = 1337\n",
    "min_sound_occurrences = 30\n",
    "# Denoising parameters\n",
    "use_rec_denoising = False\n",
    "rec_denoising_params = {'stationary': False, 'n_fft': 512, 'time_constant_s': 0.05, \n",
    "                        'freq_mask_smooth_hz': 500, 'time_mask_smooth_ms': 10}\n",
    "# Sounds metadata parameters\n",
    "classes_balance_factor = 5/7\n",
    "train_ratio = .7\n",
    "columns_to_copy = ['colony', 'ratids', 'date', 'experiment']\n",
    "# Processing features\n",
    "frequency_threshold = 3000\n",
    "sr = 22050\n",
    "n_fft = 512\n",
    "n_mel = 80\n",
    "t_dim = 64\n",
    "target_shape = (n_mel, t_dim)\n",
    "use_melspecs = True\n",
    "# Data augmentation parameters\n",
    "wave_augment_params = {'augment': False, \n",
    "                       'times_each_sound': 4, \n",
    "                       'stretching_lims': None,\n",
    "                       'add_noise_lims': (0.001, 0.005), }\n",
    "times_augment_im = 5\n",
    "#times_augment_im = 10\n",
    "augment_im = True\n",
    "# Where to store\n",
    "path_to_save = PATH_TO_PROJECT + 'models/classifier/datasets/'\n",
    "augment_str = 'no-augment' if (times_augment_im == 1 or not augment_im) else 'im-augment=%d' % times_augment_im\n",
    "dataset_name = 'hvd_%s_nfft=%d_nmel=%d_tdim=%d_rec-denoise=%s_highpass=%s' % (augment_str, n_fft, \n",
    "                                                                              n_mel, t_dim, use_rec_denoising, \n",
    "                                                                              frequency_threshold)\n",
    "random_seed = 42\n",
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2af1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 9 recordings\n"
     ]
    }
   ],
   "source": [
    "recs_metadata, recs_dict = load_recordings_metadata(path_to_recordings_metadata, recordings_metadata_name,\n",
    "                                                    dates, colonies, experiments, stages, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eadbf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config dictionary\n",
    "all_params_dict = {'sr': sr,\n",
    "                   \n",
    "                   'recs_metadata': \n",
    "                       {'dates': dates, 'colonies': colonies, 'experiments': experiments, 'stages': stages,\n",
    "                        'path_to_recordings_metadata': path_to_recordings_metadata, \n",
    "                        'recordings_metadata_name': recordings_metadata_name},\n",
    "                   \n",
    "                   'rec_denoising':\n",
    "                       {'use_rec_denoising': use_rec_denoising, 'rec_denoising_params': rec_denoising_params},\n",
    "                   \n",
    "                   'sounds_metadata':\n",
    "                       {'classes_to_drop': classes_to_drop, 'max_sounds_per_class': max_sounds_per_class, \n",
    "                        'max_sound_length': max_sound_length, 'min_sound_length': min_sound_length, \n",
    "                        'min_sound_occurrences': min_sound_occurrences,\n",
    "                        'classes_balance_factor': classes_balance_factor, 'train_ratio': train_ratio,\n",
    "                        'columns_to_copy': columns_to_copy, 'random_seed': random_seed},\n",
    "                   \n",
    "                   'features': \n",
    "                       {'target_shape': target_shape, 'frequency_threshold': frequency_threshold,\n",
    "                        'n_fft': n_fft, 'n_mel': n_mel, 'wave_augment_params': wave_augment_params, \n",
    "                        'use_melspecs': use_melspecs,  'times_augment_im': times_augment_im, \n",
    "                        'augment_im': augment_im}\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4a05536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 9 recordings\n",
      "Using 5 recordings (1424 sounds)for train and  3 recordings (467 sounds)for test\n",
      "\n",
      "############ Classes in train:############ \n",
      "\n",
      "scream    845\n",
      "sq        459\n",
      "sul        56\n",
      "tweet      35\n",
      "phee       29\n",
      "Name: cl, dtype: int64\n",
      "############ Classes in test: ############ \n",
      "\n",
      "sq        217\n",
      "scream    192\n",
      "sul        43\n",
      "phee        8\n",
      "tweet       7\n",
      "Name: cl, dtype: int64\n",
      "After balancing:\n",
      "############ Classes in train:############ \n",
      "\n",
      "scream    845\n",
      "sq        459\n",
      "sul       336\n",
      "phee      319\n",
      "tweet     315\n",
      "Name: cl, dtype: int64\n",
      "############ Classes in test: ############ \n",
      "\n",
      "sq        217\n",
      "scream    192\n",
      "sul        43\n",
      "phee        8\n",
      "tweet       7\n",
      "Name: cl, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gr1/Projects/naked-mole-rats/src/metadata_processing/process_sounds_metadata.py:37: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  sounds_metadata = pd.concat(sounds_metadata, 0).reset_index(drop=True)\n",
      "/home/gr1/Projects/naked-mole-rats/src/deep_learning/soundtype_classifier/classifier_datasets.py:26: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  return pd.concat(sounds_metadata_balanced, 0)\n",
      "/home/gr1/Projects/naked-mole-rats/src/deep_learning/soundtype_classifier/classifier_datasets.py:79: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  for sound in sounds_npy_train])\n",
      "/home/gr1/Projects/naked-mole-rats/src/deep_learning/soundtype_classifier/classifier_datasets.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  for sound in sounds_npy_test])\n",
      "/home/gr1/Projects/naked-mole-rats/src/audiodata_processing/extract_features_from_wave.py:31: FutureWarning: Pass sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft=nfft, n_mels=n_mel)\n",
      "/home/gr1/Projects/naked-mole-rats/src/deep_learning/soundtype_classifier/classifier_datasets.py:105: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  sounds_metadata_train = pd.concat([sounds_metadata_train] * times_augment_im, 0)\n",
      "/home/gr1/miniconda3/envs/nmr/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/gr1/miniconda3/envs/nmr/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved !!! \n"
     ]
    }
   ],
   "source": [
    "# Create and save datasets\n",
    "(all_classes, sounds_metadata_train, sounds_npy_train, melspecs_train,  sounds_metadata_test, \n",
    " sounds_npy_test,  melspecs_test) = create_data_for_classifier(all_params_dict, dataset_name, \n",
    "                                                               path_to_save, save=True, \n",
    "                                                               preloaded_recs_dict=recs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8b2ffc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1595 4225 2295 1680 1575]\n",
      "[  8 192 217  43   7]\n"
     ]
    }
   ],
   "source": [
    "# Print bincounts\n",
    "img_shape = melspecs_train.shape[1:]\n",
    "y_train_str = sounds_metadata_train['cl']\n",
    "y_test_str = sounds_metadata_test['cl']\n",
    "all_classes_str = sorted(list(set(y_train_str.unique()) | set(y_test_str.unique())))\n",
    "y_train = y_train_str.apply(lambda x: all_classes_str.index(x))\n",
    "y_test = y_test_str.apply(lambda x: all_classes_str.index(x))\n",
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285af2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
