{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path_to_this_notebook = os.path.abspath('.')\n",
    "PATH_TO_PROJECT = path_to_this_notebook[: path_to_this_notebook.find('notebooks')]\n",
    "sys.path.append(PATH_TO_PROJECT)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from src.preprocessing.process_sounds_metadata import generate_sounds_metadata, make_fixed_size_sounds\n",
    "from src.preprocessing.filters import filter_recs_metadata\n",
    "from src.preprocessing.load_data import load_recs_dict, load_sounds\n",
    "from src.deep_learning.create_model import create_conv_model\n",
    "from src.data_representations.process_wavs import *\n",
    "from src.data_representations.process_images import *\n",
    "from src.deep_learning.splitting import *\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to metadata\n",
    "path_to_recordings_metadata = PATH_TO_PROJECT + 'data_no-african/'\n",
    "recordings_metadata_name = 'recordings_metadata.csv'\n",
    "\n",
    "# what data to load\n",
    "dates = 'all'\n",
    "train_colonies = ['baratheon', 'stark', 'targaryen', 'dothrakia', 'freefolka']\n",
    "test_colonies = ['martell']\n",
    "experiments = 'all'\n",
    "stages = ['traced and checked', 'labeled and checked']\n",
    "\n",
    "#!\n",
    "class_augment_dict = {'sound' : 3,  'noise' : 3}\n",
    "sounds_max_length = 10000\n",
    "sounds_min_length = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softchirp          70832\n",
      "noise              35399\n",
      "weirdo              8895\n",
      "loudchirp           2614\n",
      "downsweep           1655\n",
      "grunt                715\n",
      "whistle              708\n",
      "badsplit             483\n",
      "combo                432\n",
      "upsweep              373\n",
      "combotwo             370\n",
      "scream               201\n",
      "mordent               63\n",
      "tweet                 48\n",
      "vtrill                33\n",
      "phee                  22\n",
      "invertedmordent       10\n",
      "RFIDscanner            7\n",
      "hiccup                 5\n",
      "Name: cl, dtype: int64\n",
      "softchirp    1674\n",
      "noise         315\n",
      "grunt          77\n",
      "weirdo         46\n",
      "whistle        25\n",
      "upsweep        24\n",
      "downsweep       4\n",
      "Name: cl, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load metadata\n",
    "recs_metadata = pd.read_csv(path_to_recordings_metadata + recordings_metadata_name)\n",
    "\n",
    "mask_train = filter_recs_metadata(recs_metadata, dates, train_colonies, stages, experiments)\n",
    "mask_test = filter_recs_metadata(recs_metadata, dates, test_colonies, stages, experiments)\n",
    "\n",
    "recs_for_training = recs_metadata[mask_train]\n",
    "recs_for_test = recs_metadata[mask_test]\n",
    "\n",
    "recs_dict_train = load_recs_dict(recs_for_training)\n",
    "recs_dict_test = load_recs_dict(recs_for_test)\n",
    "\n",
    "sounds_metadata_train = generate_sounds_metadata(recs_for_training).reset_index(drop=True)\n",
    "sounds_metadata_test = generate_sounds_metadata(recs_for_test).reset_index(drop=True)\n",
    "\n",
    "print(sounds_metadata_train['cl'].value_counts())\n",
    "print(sounds_metadata_test['cl'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound    36000\n",
      "noise    34429\n",
      "Name: cl, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# drop some softchirp for the sake of class balancing\n",
    "max_softchirps = 22000\n",
    "softchirps_inds = np.where(sounds_metadata_train['cl'] == 'softchirp')[0]\n",
    "np.random.shuffle(softchirps_inds)\n",
    "sounds_metadata_train = sounds_metadata_train.drop(softchirps_inds[max_softchirps :]).reset_index(drop = True)\n",
    "sounds_metadata_train['cl'] = sounds_metadata_train['cl'].apply(lambda x : 'noise' if x == 'noise' else 'sound')\n",
    "sounds_metadata_test['cl'] = sounds_metadata_test['cl'].apply(lambda x : 'noise' if x == 'noise' else 'sound' )\n",
    "                                                                \n",
    "lengths = 22050 * (sounds_metadata_train['e'] - sounds_metadata_train['s'])\n",
    "mask_normal_sounds = (lengths >= sounds_min_length) & (lengths <= sounds_max_length)\n",
    "sounds_metadata_train = sounds_metadata_train[mask_normal_sounds].reset_index(drop = True)\n",
    "print(sounds_metadata_train['cl'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 6.68 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resolution = 1024 # ~0.05 sec\n",
    "step = 512 # ~0.025 sec\n",
    "\n",
    "def process(sounds_metadata, recs_dict, resolution=1024, step=512, n_fft=512, n_mel=80):\n",
    "    sound_processing = {'stretching_lim_train' : None,\n",
    "                        'stretching_lim_test' : None,\n",
    "                        'noise_lim_train' : (0.001, 0.005),\n",
    "                        'noise_lim_test' : None,\n",
    "                        'filtering_th' : 3000\n",
    "                       }\n",
    "\n",
    "    sounds_metadata_ints_split = make_fixed_size_sounds(sounds_metadata, resolution, step)\n",
    "    sounds_npy_split = load_sounds(sounds_metadata_ints_split, recs_dict, noisy_sampling=False, timestamps='int')\n",
    "    sounds_npy_pr_iterator = process_waves(sounds_npy_split, sound_processing['stretching_lim_train'],\n",
    "                                           sound_processing['noise_lim_train'], sound_processing['filtering_th'])\n",
    "    melspecs_array = np.array(extract_melspecs(sounds_npy_pr_iterator, n_fft, n_mel))\n",
    "\n",
    "    img_shape = melspecs_array[0].shape\n",
    "    all_classes = ['noise', 'sound']\n",
    "    y_train_num = np.array([all_classes.index(yi) for yi in sounds_metadata_ints_split['cl']])\n",
    "\n",
    "    return melspecs_array, y_train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "melspecs_array_train, y_train_num = process(sounds_metadata_train, recs_dict_train, \n",
    "                                            resolution=1024, step=512, n_fft=512, n_mel=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_fixed_size_sounds(sounds_metadata, resolution=1024, step=512, sr=22050):\n",
    "    \"\"\" Changes timesstamps s.t. sounds are all of the same size \"\"\"\n",
    "    sounds_metadata_split = []\n",
    "    \n",
    "    s_ints = sounds_metadata['s'].apply(lambda x : int(sr * x))\n",
    "    e_ints = sounds_metadata['e'].apply(lambda x : int(sr * x))\n",
    "    sizes = e_ints - s_ints\n",
    "    \n",
    "    s_col_ind = list(sounds_metadata.columns).index('s')\n",
    "    e_col_ind = list(sounds_metadata.columns).index('e')\n",
    "    \n",
    "    for ind in range(len(sounds_metadata)):\n",
    "        s_int, e_int, size = s_ints.iloc[ind], e_ints.iloc[ind], sizes.iloc[ind]\n",
    "        parts_in_sound = int(size // resolution) \n",
    "        useless_space = size - parts_in_sound * resolution\n",
    "        \n",
    "        s_int_new = int(s_int + useless_space // 2)\n",
    "        e_int_new = int(e_int - useless_space // 2)\n",
    "        \n",
    "        for s_p in range(s_int_new, e_int_new + 1 - resolution, step):\n",
    "            e_p = s_p + step\n",
    "            row = list(sounds_metadata.iloc[ind])\n",
    "            row[s_col_ind] = s_p\n",
    "            row[e_col_ind] = e_p\n",
    "            sounds_metadata_split.append(tuple(row))\n",
    "            \n",
    "    return pd.DataFrame(sounds_metadata_split, columns = sounds_metadata.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
